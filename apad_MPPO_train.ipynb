{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf4a6a6c-f6f8-4204-9888-dbbdc6ae12f4",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e59969-0c4f-4ee2-a6ee-e6b1335cc503",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#!pip install sb3-contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e4c09cd-9caf-4544-a2c9-d1ee422847ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib import MaskablePPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import time\n",
    "from collections import deque\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from math import exp, log\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "376a3c02-0433-454a-962a-6c0c10fb07b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from stable_baselines3.common.utils import get_schedule_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59ea20ca-522f-4033-a5c6-e93f10073faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimerCallback(BaseCallback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def _on_step(self):\n",
    "        if self.num_timesteps % 1000 == 0:\n",
    "            elapsed = time.time() - self.start_time\n",
    "            rate = self.num_timesteps / elapsed\n",
    "            remaining = (self.locals['total_timesteps'] - self.num_timesteps) / rate\n",
    "            print(f\"Step {self.num_timesteps}, {elapsed:.0f}s elapsed, {remaining:.0f}s remaining\")\n",
    "        return True\n",
    "\n",
    "class GradNormCallback(BaseCallback):\n",
    "    def _on_step(self):\n",
    "        if hasattr(self.model.policy, 'parameters'):\n",
    "            total_norm = 0\n",
    "            for p in self.model.policy.parameters():\n",
    "                if p.grad is not None:\n",
    "                    param_norm = p.grad.data.norm(2)\n",
    "                    total_norm += param_norm.item() ** 2\n",
    "            total_norm = total_norm ** (1. / 2)\n",
    "            \n",
    "            self.logger.record(\"train/grad_norm\", total_norm)\n",
    "        return True\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# up the difficulty upon reaching certain (rolling) mean episode length thresholds\n",
    "class CurriculumCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose = 1):\n",
    "        super().__init__(verbose = verbose)\n",
    "        self.env = env\n",
    "        self.verbose = verbose\n",
    "        self.thresholds = [7.5, 5] # episode length required before upping difficulty\n",
    "        self.current_stage = 0\n",
    "        self.ep_lengths = deque(maxlen=30)\n",
    "\n",
    "    def _on_step(self):\n",
    "        infos = self.locals.get(\"infos\", [])\n",
    "        for info in infos:\n",
    "            if \"episode\" not in info:\n",
    "                continue\n",
    "                \n",
    "            ep_len = info[\"episode\"][\"l\"]\n",
    "            self.ep_lengths.append(ep_len)\n",
    "            avg_len = sum(self.ep_lengths) / len(self.ep_lengths)\n",
    "            if self.current_stage < len(self.thresholds) and avg_len > self.thresholds[self.current_stage]:\n",
    "                self.current_stage += 1\n",
    "                self.env.set_difficulty(self.current_stage)\n",
    "                if self.verbose:\n",
    "                    print(f\"Average episode length: {avg_len:.2f} â€” Switched to difficulty: {self.current_stage}\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb24b112-f78d-4537-8241-4c27e669e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Discussion below points to the constraint Simplex being a bug, not a problem with my env or training.\n",
    "# These lines turn off many validation checks, including the Simplex one causing us problems.\n",
    "#\n",
    "# Alternatively, the discussions also suggest modifying the check threshold in torch/distributions/constraints.py:: class _Simplex.\n",
    "#        # Current:\n",
    "#        return torch.all(value >= 0, dim=-1) & ((value.sum(-1) - 1).abs() < 1e-6)\n",
    "#        \n",
    "#        # Fix:\n",
    "#        tol = torch.finfo(value.dtype).eps * 10 * value.size(-1) ** 0.5\n",
    "#        return torch.all(value >= 0, dim=-1) & ((value.sum(-1) - 1).abs() < tol)\n",
    "#\n",
    "# Both seem to work. I'm going for the latter. Its possibly is making my training slower and less stable though.\n",
    "#\n",
    "# Discussion:\n",
    "# https://discuss.pytorch.org/t/distributions-categorical-fails-with-constraint-simplex-but-manual-check-passes/163209/9\n",
    "# https://github.com/pytorch/pytorch/issues/87468\n",
    "# https://github.com/Stable-Baselines-Team/stable-baselines3-contrib/issues/81\n",
    "\n",
    "# from torch.distributions import Distribution\n",
    "# Distribution.set_default_validate_args(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a08b16-8d90-4287-8a5e-4e01e2b96cfd",
   "metadata": {},
   "source": [
    "# Training Strategy: entropy rampdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a581b429-3dd6-4dba-a602-26aecb37726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apad_env import APADEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc5d2944-f9e6-45a6-a8a1-114f21ae0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(mo=None, day=None):\n",
    "   if mo is None or day is None:\n",
    "       env = APADEnv()  # random board\n",
    "   else:\n",
    "       env = APADEnv(mo, day)  # fixed board\n",
    "   return Monitor(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93035162-cf51-4c84-8178-267d95fde477",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_coef_i = 0.2\n",
    "ent_coef_f = 0.015\n",
    "D = log(ent_coef_i/ent_coef_f)\n",
    "\n",
    "n_boards = 100\n",
    "board_configs = []\n",
    "for _ in range(n_boards):\n",
    "   mo = random.randint(1, 12)\n",
    "   day = random.randint(1, 30)\n",
    "   board_configs.append((mo, day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c0032-f20a-4976-a3d3-f4875a26d729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Switching to board: (6, 7)\n",
      "ENTCOEF 0.2\n",
      "Logging to ./maskable_ppo_logs_16/PPO_1\n",
      "Step 1000, 6s elapsed, 270s remaining\n",
      "Step 2000, 11s elapsed, 263s remaining\n",
      "Step 3000, 17s elapsed, 259s remaining\n",
      "Step 4000, 22s elapsed, 255s remaining\n",
      "Step 5000, 28s elapsed, 249s remaining\n",
      "Step 6000, 33s elapsed, 245s remaining\n",
      "Step 7000, 39s elapsed, 239s remaining\n",
      "Step 8000, 44s elapsed, 233s remaining\n",
      "Step 9000, 50s elapsed, 227s remaining\n",
      "Step 10000, 55s elapsed, 221s remaining\n",
      "Step 11000, 61s elapsed, 216s remaining\n",
      "Step 12000, 67s elapsed, 211s remaining\n",
      "Step 13000, 72s elapsed, 205s remaining\n",
      "Step 14000, 77s elapsed, 199s remaining\n",
      "Step 15000, 83s elapsed, 193s remaining\n",
      "Step 16000, 88s elapsed, 188s remaining\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.5      |\n",
      "|    ep_rew_mean     | -0.073   |\n",
      "| time/              |          |\n",
      "|    fps             | 181      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 90       |\n",
      "|    total_timesteps | 16384    |\n",
      "| train/             |          |\n",
      "|    grad_norm       | 0        |\n",
      "---------------------------------\n",
      "Step 17000, 109s elapsed, 211s remaining\n",
      "Step 18000, 114s elapsed, 203s remaining\n",
      "Step 19000, 120s elapsed, 196s remaining\n",
      "Step 20000, 125s elapsed, 188s remaining\n",
      "Step 21000, 131s elapsed, 181s remaining\n",
      "Step 22000, 136s elapsed, 174s remaining\n",
      "Step 23000, 142s elapsed, 167s remaining\n",
      "Step 24000, 148s elapsed, 160s remaining\n",
      "Step 25000, 154s elapsed, 154s remaining\n"
     ]
    }
   ],
   "source": [
    "current_mo, current_day = board_configs[0]\n",
    "env = SubprocVecEnv([lambda mo=current_mo, day=current_day: make_env(mo, day) for _ in range(8)])\n",
    "model = MaskablePPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    tensorboard_log=\"./maskable_ppo_logs_16/\",\n",
    "    ent_coef= ent_coef_i,\n",
    "    #learning_rate=0.0004,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "total_timesteps = 2000000\n",
    "checkpoint_interval = 50000\n",
    "for i in range(0, total_timesteps, checkpoint_interval):\n",
    "    reset = True if i == 0 else False\n",
    "    remaining_steps = min(checkpoint_interval, total_timesteps - i)\n",
    "    progress = i / total_timesteps\n",
    "\n",
    "    # new board to train on\n",
    "    current_mo, current_day = random.choice(board_configs)\n",
    "    env = SubprocVecEnv([lambda mo=current_mo, day=current_day: make_env(mo, day) for _ in range(8)])\n",
    "    model.set_env(env)\n",
    "    print(f\"Switching to board: ({current_mo}, {current_day})\")\n",
    "   \n",
    "    if progress < 0.9:\n",
    "        model.ent_coef = ent_coef_i * exp(-1*D*progress)\n",
    "    \n",
    "    print(f\"ENTCOEF {model.ent_coef}\")\n",
    "    \n",
    "    model.learn(total_timesteps=remaining_steps, reset_num_timesteps=reset, callback=[TimerCallback(),GradNormCallback()])\n",
    "    \n",
    "    #if i % 1000000 == 0:\n",
    "    model.save(f\"mppo_model_v0_{i}\")\n",
    "\n",
    "model.save(f\"mppo_model_v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c8550d-0d8e-4c2b-97c1-7c893a743b92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99b5815-aa1b-448b-b505-75f3296b3f29",
   "metadata": {},
   "source": [
    "## Training strategy: incremental difficulty rampup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0927914-10fc-4e1b-bcc6-586a1a12b605",
   "metadata": {},
   "source": [
    "### step 1: no date, 6 pieces = win\n",
    "v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01481d2c-8613-4ee9-9e6e-507882736782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = APADEnv(-1,-1,2)\n",
    "model = None\n",
    "model = MaskablePPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    tensorboard_log=\"./maskable_ppo_logs_14/\",\n",
    "    ent_coef=0.1,\n",
    "    learning_rate=0.003,\n",
    "    verbose=1,\n",
    ")\n",
    "model.learn(total_timesteps=75000, callback=[TimerCallback(), GradNormCallback()])\n",
    "model.save(f\"mppo_model_v0_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be7f7b-d854-4866-8e4a-5612f70ce2dc",
   "metadata": {},
   "source": [
    "### step 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6e6c83-ec8c-429b-8142-67995f146c8f",
   "metadata": {},
   "source": [
    "a) no date, 7 pieces\n",
    "\n",
    "v0a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303af06a-a504-42da-afff-6b76afc41899",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskablePPO.load(\"mppo_model_v0\")\n",
    "env = APADEnv(-1,-1,1)\n",
    "model.set_env(env)\n",
    "model.learn(100000, reset_num_timesteps=True)\n",
    "model.save(f\"mppo_model_v0a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348e0cbe-a852-41bd-b70d-162622144ac6",
   "metadata": {},
   "source": [
    "b) day only, 6 pieces\n",
    "\n",
    "v0b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05c29e-7ff8-4310-bcd7-6b48896178e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskablePPO.load(\"mppo_model_v0\")\n",
    "env = APADEnv(-1,None,2)\n",
    "model.set_env(env)\n",
    "model.learn(100000, reset_num_timesteps=True)\n",
    "model.save(f\"mppo_model_v0b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa73bd42-fc7f-472e-b262-02f3f7480ba9",
   "metadata": {},
   "source": [
    "c) month only, 6 pieces\n",
    "\n",
    "v0c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7360ba4-ae32-4586-8991-35a64f7b985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskablePPO.load(\"mppo_model_v0\")\n",
    "env = APADEnv(None,-1,2)\n",
    "model.set_env(env)\n",
    "model.learn(100000, reset_num_timesteps=True)\n",
    "model.save(f\"mppo_model_v0c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5704a97b-99fc-421b-9175-1223c9acc8fc",
   "metadata": {},
   "source": [
    "## Training strategy: Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6b6330-6fc9-481c-88e9-eb1bf69e3bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_timesteps = 100000\n",
    "#checkpoint_interval = 25000\n",
    "#for i in range(0, total_timesteps, checkpoint_interval):\n",
    "#    remaining_steps = min(checkpoint_interval, total_timesteps - i)\n",
    "#    if i == 0:\n",
    "#        model.learn(total_timesteps=remaining_steps, reset_num_timesteps=True, callback=[TimerCallback(),GradNormCallback()])\n",
    "#    else:\n",
    "#        model.learn(total_timesteps=remaining_steps, reset_num_timesteps=False, callback=[TimerCallback(),GradNormCallback()])\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3ff6a-b02b-4466-be0b-f5ca09c4957e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = APADEnv(-1)\n",
    "#env.reset()\n",
    "model = None\n",
    "model = MaskablePPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    tensorboard_log=\"./maskable_ppo_logs_10/\",\n",
    "    ent_coef=0.03,\n",
    "    verbose=1,\n",
    ")\n",
    "total_timesteps = 300000\n",
    "checkpoint_interval = 50000\n",
    "for i in range(0, total_timesteps, checkpoint_interval):\n",
    "    remaining_steps = min(checkpoint_interval, total_timesteps - i)\n",
    "    if i == 0:\n",
    "        model.learn(total_timesteps=remaining_steps, reset_num_timesteps=True, callback=[TimerCallback(),GradNormCallback()])\n",
    "    else:\n",
    "        model.learn(total_timesteps=remaining_steps, reset_num_timesteps=False, callback=[TimerCallback(),GradNormCallback()])\n",
    "    model.save(f\"mppo_model_{11}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70ee7df-1acf-4574-995e-e381dd8087b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = APADEnv(-1,-1)\n",
    "env.reset()\n",
    "model = None\n",
    "model = MaskablePPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    #n_steps = 512,\n",
    "    tensorboard_log=\"./maskable_ppo_logs_9/\",\n",
    "    verbose=1,\n",
    ")\n",
    "model.learn(total_timesteps=50000, reset_num_timesteps=False, callback=[TimerCallback(), GradNormCallback()])\n",
    "model.save(f\"mppo_model_9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bff7055-60a2-4ebf-ba6e-cb317ce02fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    env.reset()\n",
    "    model = None\n",
    "    model = MaskablePPO(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        #n_steps = 512,\n",
    "        tensorboard_log=\"./maskable_ppo_logs_9/\",\n",
    "        verbose=1,\n",
    "    )\n",
    "    model.learn(total_timesteps=50000, reset_num_timesteps=True, callback=[TimerCallback(), GradNormCallback()])\n",
    "    model.save(f\"mppo_model_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce75301-3bee-4678-8ae6-3561b390ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mppo_model_25k_2025-06-19_1500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c01262e-9475-406c-b9e6-e37a9002f2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
